\documentclass[../body.tex]{subfiles}
\begin{document}
\subsection{Метод наискорейшего спуска}
Важнейший элемент градиентного метода первого порядка - выбор параметра $\alpha$. Широко используется вариант выбора шага, при котором $\alpha$ находится в рузультате решения задачи одномерной минимизации, то есть из условия: $$f(x_k - \alpha_k \cdot \nabla f(x_k)) = min f(x_k - \alpha \nabla f(x_k)), \alpha \geq 0.$$

\SetKwRepeat{Do}{do}{while}
\begin{algorithm}[H]\label{gradient}
	\KwData{$eps > 0$ - параметр, характеризующий условие окончания вычислений;\newline $x_0$ - начальное приближение.}
	\KwResult{$x_{min}$ - значение аргумента, удовлетворяющее условию $||\nabla f(x_k)||^2 < eps$.}
	k := 0\;
	\Do{$||\nabla f(x_k)||^2 \geq eps$}{
		Вычисляем $\nabla f(x_k)$\;
		Определяем $\alpha_k$, исходя из условия $min f(x_k - \alpha \nabla f(x_k)), \alpha \geq 0$\;
		$x_{k+1} := x_k - \alpha_k \nabla f(x_k)$\;
		$k := k + 1$\;
	}
	\caption{Метод наискорейшего спуска}
\end{algorithm}

Заметим, что строка 4 - основной шаг алгоритма (\ref{gradient}), ведь тут вычисляется параметр $\alpha_k$. Здесь мы воспользуемся методом одномерной минимизации Золотого Сечения, который подробно описан нами в предыдущей ЛР.
\end{document}